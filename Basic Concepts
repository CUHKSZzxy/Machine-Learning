# Machine Learning 

## What is Machine Learning?

## Supervised learning Unsupervised learning
Supervised learning: we have taught the computer about the "true, false" result for each element in dataset Unsupervised learning: 
the computers are not told about the "true, false" result for each element in the dataset, it only knows that there exists a dataset

## Linear regression & classification (机器学习两大问题：线性回归问题和分类问题)
Linear regression: solve continuous case and output continuous result (e.g. the price prediction of house) 
classification: consider data as discrete, output a "0 or 1" result


## 监督学习(supervised learning)

​	特点：监督学习是使用已知正确答案的示例来训练网络。已知数据和其一一对应的标签，训练一个预测模型，将输入数据映射到标签的过程。
​	常见应用场景：监督式学习的常见应用场景如分类问题和回归问题。
​	算法举例：常见的有监督机器学习算法包括支持向量机(Support Vector Machine, SVM)，朴素贝叶斯(Naive Bayes)，逻辑回归(Logistic Regression)，K近邻(K-Nearest Neighborhood, KNN)，决策树(Decision Tree)，随机森林(Random Forest)，AdaBoost以及线性判别分析(Linear Discriminant Analysis, LDA)等。
深度学习(Deep Learning)也是大多数以监督学习的方式呈现。

## 非监督式学习(unsupervised learning)

​	定义：在非监督式学习中，数据并不被特别标识，适用于你具有数据集但无标签的情况。学习模型是为了推断出数据的一些内在结构。
​	常见应用场景：常见的应用场景包括关联规则的学习以及聚类等。
​	算法举例：常见算法包括Apriori算法以及k-Means算法。

## 半监督式学习

​	特点：在此学习方式下，输入数据部分被标记，部分没有被标记，这种学习模型可以用来进行预测。
​	常见应用场景：应用场景包括分类和回归，算法包括一些对常用监督式学习算法的延伸，通过对已标记数据建模，在此基础上，对未标记数据进行预测。
​	算法举例：常见算法如图论推理算法（Graph Inference）或者拉普拉斯支持向量机（Laplacian SVM）等。

## 弱监督学习

​	特点：弱监督学习可以看做是有多个标记的数据集合，次集合可以是空集，单个元素，或包含多种情况（没有标记，有一个标记，和有多个标记）的多个元素。 
数据集的标签是不可靠的，这里的不可靠可以是标记不正确，多种标记，标记不充分，局部标记等。已知数据和其一一对应的弱标签，训练一个智能算法，将输入数据映射到一组更强的标签的过程。标签的强弱指的是标签蕴含的信息量的多少，比如相对于分割的标签来说，分类的标签就是弱标签。
​	算法举例：举例，给出一张包含气球的图片，需要得出气球在图片中的位置及气球和背景的分割线，这就是已知弱标签学习强标签的问题。
​	在企业数据应用的场景下， 人们最常用的可能就是监督式学习和非监督式学习的模型。 在图像识别等领域，由于存在大量的非标识的数据和少量的可标识数据， 目前半监督式学习是一个很热的话题。

## 监督学习有哪些步骤

​	监督学习是使用已知正确答案的示例来训练网络，每组训练数据有一个明确的标识或结果。想象一下，我们可以训练一个网络，让其从照片库中（其中包含气球的照片）识别出气球的照片。以下就是我们在这个假设场景中所要采取的步骤。

**步骤1：数据集的创建和分类** 首先，浏览你的照片（数据集），确定所有包含气球的照片，并对其进行标注。然后，将所有照片分为训练集和验证集。目标就是在深度网络中找一函数，这个函数输入是任意一张照片，当照片中包含气球时，输出1，否则输出0。

**步骤2：数据增强（Data Augmentation）** 	当原始数据搜集和标注完毕，一般搜集的数据并不一定包含目标在各种扰动下的信息。数据的好坏对于机器学习模型的预测能力至关重要，因此一般会进行数据增强。对于图像数据来说，数据增强一般包括，图像旋转，平移，颜色变换，裁剪，仿射变换等。

**步骤3：特征工程（Feature Engineering）** 	一般来讲，特征工程包含特征提取和特征选择。常见的手工特征(Hand-Crafted Feature)有尺度不变特征变换(Scale-Invariant Feature Transform, SIFT)，方向梯度直方图(Histogram of Oriented Gradient, HOG)等。
由于手工特征是启发式的，其算法设计背后的出发点不同，将这些特征组合在一起的时候有可能会产生冲突，
如何将组合特征的效能发挥出来，使原始数据在特征空间中的判别性最大化，
就需要用到特征选择的方法。在深度学习方法大获成功之后，人们很大一部分不再关注特征工程本身。
因为，最常用到的卷积神经网络(Convolutional Neural Networks, CNNs)本身就是一种特征提取和选择的引擎。研究者提出的不同的网络结构、正则化、归一化方法实际上就是深度学习背景下的特征工程。

**步骤4：构建预测模型和损失** 	将原始数据映射到特征空间之后，也就意味着我们得到了比较合理的输入。下一步就是构建合适的预测模型得到对应输入的输出。
而如何保证模型的输出和输入标签的一致性，就需要构建模型预测和标签之间的损失函数，常见的损失函数(Loss Function)有交叉熵、均方差等。
通过优化方法不断迭代，使模型从最初的初始化状态一步步变化为有预测能力的模型的过程，实际上就是学习的过程。

**步骤5：训练** 	选择合适的模型和超参数进行初始化，其中超参数比如支持向量机中核函数、误差项惩罚权重等。当模型初始化参数设定好后，将制作好的特征数据输入到模型，通过合适的优化方法不断缩小输出与标签之间的差距，当迭代过程到了截止条件，就可以得到训练好的模型。
优化方法最常见的就是梯度下降法及其变种，使用梯度下降法的前提是优化目标函数对于模型是可导的。

**步骤6：验证和模型选择**  训练完训练集图片后，需要进行模型测试。利用验证集来验证模型是否可以准确地挑选出含有气球在内的照片。 	
在此过程中，通常会通过调整和模型相关的各种事物（超参数）来重复步骤2和3，诸如里面有多少个节点，有多少层，使用怎样的激活函数和损失函数，如何在反向传播阶段积极有效地训练权值等等。

**步骤7：测试及应用** 	当有了一个准确的模型，就可以将该模型部署到你的应用程序中。你可以将预测功能发布为API（Application Programming Interface, 应用程序编程接口）调用，并且你可以从软件中调用该API，从而进行推理并给出相应的结果。


# Some Algorithms to implement machine learning
## Gradint descent: 
when the data set is large, approximately 10000*10000 matrix, it is more efficient
but it needs to choose an appropriate å (学习速率), avoid the possibility of missing the global min or diverging

technique of gradint descent:
to make this process faster, if two feature's range is quite different, we need to change the scala, make two range relatively
close to each other, say -1 to 1 (actual do not need to be precise, say -3 to 3, -1/3 to 1/3 is also good)

## Norm equation:
when the data set is "small", it is fast and more efficient than the gradint descent, since it can compute the thetas
but when the data set is quite large, it is time-consuming to computing, say 10000*10000 matrix's inverse. But it works pretty 
good when the data is relatively small

***(something from Linear Algebra summer session)
Best rank one approximation, use a set of rank one matrix to approximate a matrix. Complexity is reduced from O(n^2) to O(n)
save the storage


2.8.2 分类算法的评估方法
​	分类评估方法主要功能是用来评估分类算法的好坏，而评估一个分类器算法的好坏又包括许多项指标。了解各种评估方法，在实际应用中选择正确的评估方法是十分重要的。

几个常用术语 ​	这里首先介绍几个常见的模型评价术语，现在假设我们的分类目标只有两类，计为正例（positive）和负例（negative）分别是：

True positives(TP): 被正确地划分为正例的个数，即实际为正例且被分类器划分为正例的实例数；
False positives(FP): 被错误地划分为正例的个数，即实际为负例但被分类器划分为正例的实例数；
False negatives(FN):被错误地划分为负例的个数，即实际为正例但被分类器划分为负例的实例数；
True negatives(TN): 被正确地划分为负例的个数，即实际为负例且被分类器划分为负例的实例数。　
​	表2-2 四个术语的混淆矩阵

图2-3 术语的混淆矩阵

表2-2是这四个术语的混淆矩阵，做以下说明： 1）P=TP+FN表示实际为正例的样本个数。 
2）True、False描述的是分类器是否判断正确。 
3）Positive、Negative是分类器的分类结果，如果正例计为1、负例计为-1，即positive=1、negative=-1。用1表示True，-1表示False，那么实际的类标=TF*PN，TF为true或false，PN为positive或negative。 
4）例如True positives(TP)的实际类标=1*1=1为正例，False positives(FP)的实际类标=(-1)*1=-1为负例，False negatives(FN)的实际类标=(-1)*(-1)=1为正例，True negatives(TN)的实际类标=1*(-1)=-1为负例。

评价指标

正确率（accuracy） 正确率是我们最常见的评价指标，accuracy = (TP+TN)/(P+N)，正确率是被分对的样本数在所有样本数中的占比，通常来说，正确率越高，分类器越好。

错误率（error rate) 错误率则与正确率相反，描述被分类器错分的比例，error rate = (FP+FN)/(P+N)，对某一个实例来说，分对与分错是互斥事件，所以accuracy =1 - error rate。

灵敏度（sensitivity） sensitivity = TP/P，表示的是所有正例中被分对的比例，衡量了分类器对正例的识别能力。

特异性（specificity) specificity = TN/N，表示的是所有负例中被分对的比例，衡量了分类器对负例的识别能力。

精度（precision） precision=TP/(TP+FP)，精度是精确性的度量，表示被分为正例的示例中实际为正例的比例。

召回率（recall） 召回率是覆盖面的度量，度量有多个正例被分为正例，recall=TP/(TP+FN)=TP/P=sensitivity，可以看到召回率与灵敏度是一样的。

其他评价指标 计算速度：分类器训练和预测需要的时间； 鲁棒性：处理缺失值和异常值的能力； 
可扩展性：处理大数据集的能力； 
可解释性：分类器的预测标准的可理解性，像决策树产生的规则就是很容易理解的，而神经网络的一堆参数就不好理解，我们只好把它看成一个黑盒子。

精度和召回率反映了分类器分类性能的两个方面。如果综合考虑查准率与查全率，可以得到新的评价指标F1-score，也称为综合分类率：$F1=\frac{2 \times precision \times recall}{precision + recall}​$。

为了综合多个类别的分类情况，评测系统整体性能，经常采用的还有微平均F1（micro-averaging）和宏平均F1（macro-averaging ）两种指标。

（1）宏平均F1与微平均F1是以两种不同的平均方式求的全局F1指标。

（2）宏平均F1的计算方法先对每个类别单独计算F1值，再取这些F1值的算术平均值作为全局指标。

（3）微平均F1的计算方法是先累加计算各个类别的a、b、c、d的值，再由这些值求出F1值。

（4）由两种平均F1的计算方式不难看出，宏平均F1平等对待每一个类别，所以它的值主要受到稀有类别的影响，而微平均F1平等考虑文档集中的每一个文档，所以它的值受到常见类别的影响比较大。



线性回归与逻辑回归的区别如下描述：

（1）线性回归的样本的输出，都是连续值，$ y\in (-\infty ,+\infty )$，而逻辑回归中$y\in (0,1)$，只能取0和1。

（2）对于拟合函数也有本质上的差别：

​	线性回归：$f(x)=\theta ^{T}x=\theta _{1}x _{1}+\theta _{2}x _{2}+...+\theta _{n}x _{n}$

​	逻辑回归：$f(x)=P(y=1|x;\theta )=g(\theta ^{T}x)$，其中，$g(z)=\frac{1}{1+e^{-z}}$

​	可以看出，线性回归的拟合函数，是对f(x)的输出变量y的拟合，而逻辑回归的拟合函数是对为1类样本的概率的拟合。

​	那么，为什么要以1类样本的概率进行拟合呢，为什么可以这样拟合呢？

​	$\theta ^{T}x=0$就相当于是1类和0类的决策边界：

​	当$\theta ^{T}x>0$，则y>0.5；若$\theta ^{T}x\rightarrow +\infty $，则$y \rightarrow 1 $，即y为1类;

​	当$\theta ^{T}x<0$，则y<0.5；若$\theta ^{T}x\rightarrow -\infty $，则$y \rightarrow 0 $，即y为0类;∫^2



这个时候就能看出区别，在线性回归中$\theta ^{T}x$为预测值的拟合函数；而在逻辑回归中$\theta ^{T}x$为决策边界。下表2-3为线性回归和逻辑回归的区别。

​	表2-3 线性回归和逻辑回归的区别

|              | 线性回归   | 逻辑回归     |
| ------------ | ---------- | ------------ |
| 目的         | 预测       | 分类         |
| $y^{(i)}$    | 未知       | （0,1）      |
| 函数         | 拟合函数   | 预测函数     |
| 参数计算方式 | 最小二乘法 | 极大似然估计 |

下面具体解释一下：


1. 拟合函数和预测函数什么关系呢？简单来说就是将拟合函数做了一个逻辑函数的转换，转换后使得$y^{(i)} \in (0,1)$;
2. 最小二乘和最大似然估计可以相互替代吗？回答当然是不行了。我们来看看两者依仗的原理：最大似然估计是计算使得数据出现的可能性最大的参数，依仗的自然是Probability。而最小二乘是计算误差损失。
