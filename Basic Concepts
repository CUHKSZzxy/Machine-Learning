# Machine Learning 

## 监督学习有哪些步骤?
*监督学习是使用已知正确答案的示例来训练网络，每组训练数据有一个明确的标识或结果。想象一下，我们可以训练一个网络，让其从照片库中（其中包含气球的照片）识别出气球的照片。
以下就是我们在这个假设场景中所要采取的步骤。

*步骤1：数据集的创建和分类** 首先，浏览你的照片（数据集），确定所有包含气球的照片，并对其进行标注。然后，将所有照片分为训练集和验证集。
  目标就是在深度网络中找一函数，这个函数输入是任意一张照片，当照片中包含气球时，输出1，否则输出0。
  
*步骤2：数据增强（Data Augmentation）
  当原始数据搜集和标注完毕，一般搜集的数据并不一定包含目标在各种扰动下的信息。数据的好坏对于机器学习模型的预测能力至关重要，因此一般会进行数据增强。
  对于图像数据来说，数据增强一般包括，图像旋转，平移，颜色变换，裁剪，仿射变换等。
  
*步骤3：特征工程（Feature Engineering）
  一般来讲，特征工程包含特征提取和特征选择。常见的手工特征(Hand-Crafted Feature)有尺度不变特征变换(Scale-Invariant Feature Transform, SIFT)，方向梯度直方图(Histogram of Oriented Gradient, HOG)等。
  由于手工特征是启发式的，其算法设计背后的出发点不同，将这些特征组合在一起的时候有可能会产生冲突，
  如何将组合特征的效能发挥出来，使原始数据在特征空间中的判别性最大化，
  就需要用到特征选择的方法。在深度学习方法大获成功之后，人们很大一部分不再关注特征工程本身。
  因为，最常用到的卷积神经网络(Convolutional Neural Networks, CNNs)本身就是一种特征提取和选择的引擎。研究者提出的不同的网络结构、正则化、归一化方法实际上就是深度学习背景下的特征工程。
  
*步骤4：构建预测模型和损失
  将原始数据映射到特征空间之后，也就意味着我们得到了比较合理的输入。下一步就是构建合适的预测模型得到对应输入的输出。
  而如何保证模型的输出和输入标签的一致性，就需要构建模型预测和标签之间的损失函数，常见的损失函数(Loss Function)有交叉熵、均方差等。
  通过优化方法不断迭代，使模型从最初的初始化状态一步步变化为有预测能力的模型的过程，实际上就是学习的过程。
  
*步骤5：训练
  选择合适的模型和超参数进行初始化，其中超参数比如支持向量机中核函数、误差项惩罚权重等。当模型初始化参数设定好后，将制作好的特征数据输入到模型，通过合适的优化方法不断缩小输出与标签之间的差距，
  当迭代过程到了截止条件，就可以得到训练好的模型。
  优化方法最常见的就是梯度下降法及其变种，使用梯度下降法的前提是优化目标函数对于模型是可导的。
  
*步骤6：验证和模型选择
  训练完训练集图片后，需要进行模型测试。利用验证集来验证模型是否可以准确地挑选出含有气球在内的照片。 	
  在此过程中，通常会通过调整和模型相关的各种事物（超参数）来重复步骤2和3，诸如里面有多少个节点，有多少层，使用怎样的激活函数和损失函数，如何在反向传播阶段积极有效地训练权值等等。
  
*步骤7：测试及应用
  当有了一个准确的模型，就可以将该模型部署到你的应用程序中。你可以将预测功能发布为API（Application Programming Interface, 应用程序编程接口）调用，并且你可以从软件中调用该API，从而进行推理并给出相应的结果。

## 内容大纲和提要
* 监督学习，无监督学习（supervised and unspuervised learning）
** Supervised learning Unsupervised learning
Supervised learning: we have taught the computer about the "true, false" result for each element in dataset Unsupervised learning: 
the computers are not told about the "true, false" result for each element in the dataset, it only knows that there exists a dataset

* 线性回归，分类（linear regression and classification）logistic regression
** Linear regression & classification (机器学习两大问题：线性回归问题和分类问题)
Linear regression: solve continuous case and output continuous result (e.g. the price prediction of house) 
classification: consider data as discrete, output a "0 or 1" result

* 假设函数（hypothesis function）

* 损失函数，代价函数（loss function and cost function）

* 梯度下降（gradiint descent）可用矢量放缩（scaling）优化收敛速度
** Gradint descent: 
when the data set is large, approximately 10000*10000 matrix, it is more efficient
but it needs to choose an appropriate å (学习速率), avoid the possibility of missing the global min or diverging
** technique of gradint descent:
to make this process faster, if two feature's range is quite different, we need to change the scala, make two range relatively
close to each other, say -1 to 1 (actual do not need to be precise, say -3 to 3, -1/3 to 1/3 is also good)

* 利用线代知识向量化 x^i_j    j_th feature in i_th data set
** why we need bias unit in the formula? 
    since in the hypothesis function, there is a theta_0, for convienience of computation, just assume x_0 = 1, then we have theta_0*x_0

* 高级优化（advanced optimization）公式求偏导，最小二乘法（Linear Algebra）当data set ≥ 10000*10000，考虑梯度下降
  局部梯度下降，每次计算不用所有data set
** Norm equation:
when the data set is "small", it is fast and more efficient than the gradint descent, since it can compute the thetas
but when the data set is quite large, it is time-consuming to computing, say 10000*10000 matrix's inverse. But it works pretty 
good when the data is relatively small

* 欠拟合，过拟合问题（overfitting）

* 正则化（regularization）在cost function中加入theta项，使得结果趋于光滑 ∑theta^2, from 1 to n, not include bias unit（偏差项）

* 神经元，神经网络（neuron,neuron network）*可利用线代知识向量化

* 激活函数（activation function/ actually just our sigmoid function）

* 向前传播（forward propagation）
** “非”逻辑运算（negation）在预期得到非结果的变量前加一个很大的负的权重（weight/just theta in neural network）e.g. -20*x_1 对x_1的非运算
  二元分类（binary classification） 0 or 1

* 多分类问题（in neural network）（multi-class classification）单分类的拓展，就是将输出层改成多个输出的

* 代价函数（in neural network）is the same as the regularization form of the cost function in logistic regression

* 反向传播算法（back propagation）用于计算导数项

* delta^l_j error term of node j in layer l

* 梯度检测（不是梯度下降），用于防止反向传播中可能出现的错误。参数epsilon ≈ 10^-4

* 随机初始化

* 神经网络输入层单元个数=输入矢量的维数，输出层#=输出层#，隐藏层一般来说越多越好，各个隐藏层单元个数一般来说一致，是输出层的若干倍
** details about NNs
  ai(j) - activation of unit i in layer j 
So, a12 - is the activation of the 1st unit in the second layer
By activation, we mean the value which is computed and output by that node
 Ɵ(j) - matrix of parameters controlling the function mapping from layer j to layer j + 1
Parameters for controlling mapping from one layer to the next
If network has 
sj units in layer j and 
sj+1 units in layer j + 1 
Then Ɵj will be of dimensions [s_(j+1) * s_j + 1]
Because
sj+1 is equal to the number of units in layer (j + 1)
is equal to the number of units in layer j, plus an additional unit
Looking at the Ɵ matrix
Column length is the number of units in the following layer
Row length is the number of units in the current layer + 1 (because we have to map the bias unit)
So, if we had two layers - 101 and 21 units in each
Then Ɵj would be = [21 x 102]
** e.g. of our representation
Ɵ_(13)^1 = means
lower number:
1 - we're mapping to node 1 in layer l+1
3 - we're mapping from node 3 in layer l
upper number:
1 - we're mapping from layer 1

*训练集，测试集三七分，元素要随机取
model selection problem
训练集（training set），验证集（cross validation set）cv，测试集（test set）
6,2,2分
对应的cost function为 J_train, J_cv, J_test

*诊断偏差（bias）和方差（variance）as a function of the degree of polynomial（error - degree）
smaller degree -> high bias（underfitting）both training & cross validation error are high（two errors approximately equal to each other）
intermediate degree -> just right
larger degree -> high variance（overfitting）training error low, cross validation error high 

*bias and variance as a function of the regularization parameter lamda（error - lamda）
here, we define J_ train & J_cv as something without regularization term
How to pick a regularization parameter lamda?
plot lamda-error figure
larger lamda -> high bias（underfitting）both training & cross validation error are high（two errors approximately equal to each other）  
intermediate lamda -> just right
samller lamda -> high variance（overfitting）training error low, cross validation error high 

* 学习曲线（learning curves）（lamda - m） m is the number of our training set, artificially pick certain number of training set
smaller m -> J_train smaller, J_cv larger. Since it fit a small training set very well, but its generalizing ability（泛化能力）is bad
larger m -> J_train larger, J_cv smaller. Since it becomes harder to fit numerous data with our hypothesis function, but it will have a good generalizing ability 
high bias 右开窄喇叭口，train, cv error 都很高，而且当m增大，两者几乎相同
** interesting fact
if a algorithm suffers from a high bias problem, more data won't help us

high variance 右开宽喇叭口，train error 逐渐增大，但相对还是较小的，cv error 逐渐减小，但是值相对还是较大，特点：train error 和 cv error之间的gap很大
** interesting fact
if a algorithm suffers from a high variance problem, more data will help us

* DECIDE WHAT TO DO NEXT (how to evaluate and select a machine learning model)
** 
Get more training examples -> fix high variance
Try smaller set of feature -> fix high variance
Try getting additional features -> fix high bias
Try adding polynomila features -> fix high bias
Try decreasing lamda -> fix high bias
Try increasing lamda -> fix high variance







